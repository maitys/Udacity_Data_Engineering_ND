{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b2b0579",
   "metadata": {},
   "source": [
    "# **<font color='royalblue' face=\"Trebuchet MS\" size=\"6\" >Project: Data Lake - Testing Work**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edb0865a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d49a533bb264279b115e2fb83d03db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>2</td><td>application_1653931796932_0003</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-81-218.ec2.internal:20888/proxy/application_1653931796932_0003/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-87-160.ec2.internal:8042/node/containerlogs/container_1653931796932_0003_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##########################\n",
    "#### Import Libraries ####\n",
    "##########################\n",
    "from datetime import datetime\n",
    "import os, time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, dayofweek, date_format\n",
    "from pyspark.sql.types import TimestampType, DateType, IntegerType\n",
    "from pyspark.sql.functions import monotonically_increasing_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25104b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de10649614043bfbd432590d1fb9d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##############################\n",
    "#### Create Spark Session ####\n",
    "##############################\n",
    "def create_spark_session():\n",
    "    spark = SparkSession.builder.config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\").getOrCreate()\n",
    "    return spark\n",
    "\n",
    "spark = create_spark_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb07a7b",
   "metadata": {},
   "source": [
    "# **<font color='royalblue' face=\"Trebuchet MS\" size=\"5\" >1. Setup Function : `process_song_data`**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0134fac6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00110d6c65be4f5985281e1c19d179ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to run: 22.6444 seconds\n",
      "**************************************************"
     ]
    }
   ],
   "source": [
    "# Set file Path\n",
    "input_data = \"s3://udacity-dend/\"\n",
    "input_song_data = input_data + 'song_data/A/B/C/*.json'\n",
    "\n",
    "# Load raw data\n",
    "start_time = time.time()\n",
    "df_song_data = spark.read.json(input_song_data)\n",
    "print(\"Total time to run: {} seconds\".format(round((time.time() - start_time),4)))\n",
    "print(\"*\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18daa5c",
   "metadata": {},
   "source": [
    "# **<font color='indianred' face=\"Trebuchet MS\" size=\"4\" >1.1 Process `songs` table**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da8987ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a8bc01112d43cba3562f2300535ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- duration: float (nullable = true)\n",
      "\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "|           song_id|               title|         artist_id|year| duration|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "|SOQFYBD12AB0182188|               Intro|ARAADXM1187FB3ECDB|1999| 67.63057|\n",
      "|SOFIUVJ12A8C13C296|Will You Tell Me ...|AR9OEB71187B9A97C6|2005|397.16525|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "only showing top 2 rows\n",
      "\n",
      "**************************************************\n",
      "Total time to run: 3.817 seconds\n",
      "**************************************************\n",
      "root\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- duration: float (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      "\n",
      "+------------------+--------------------+---------+----+------------------+\n",
      "|           song_id|               title| duration|year|         artist_id|\n",
      "+------------------+--------------------+---------+----+------------------+\n",
      "|SOCEMJV12A6D4F7667|Giant Steps (Alte...|220.44688|   0|ARIOZCU1187FB3A3DC|\n",
      "|SODREIN12A58A7F2E5|A Whiter Shade Of...|326.00772|   0|ARLTWXK1187FB5A3F8|\n",
      "+------------------+--------------------+---------+----+------------------+\n",
      "only showing top 2 rows"
     ]
    }
   ],
   "source": [
    "# Create table\n",
    "df_songs_table = df_song_data.select('song_id', 'title', 'artist_id', 'year', 'duration').dropDuplicates()\n",
    "\n",
    "# Fix Datatypes\n",
    "df_songs_table = df_songs_table.withColumn(\"duration\",col(\"duration\").cast('float'))\n",
    "df_songs_table = df_songs_table.withColumn(\"year\",col(\"year\").cast('integer'))\n",
    "\n",
    "# Create Temp View\n",
    "# df_songs_table.createOrReplaceTempView('songs_table')\n",
    "df_songs_table.printSchema()\n",
    "df_songs_table.show(2)\n",
    "print(\"*\" * 50)\n",
    "\n",
    "# Write table to s3 --> parquet files partitioned by year and artist\n",
    "output_data = 's3a://maitys-sparkify-outputs/'\n",
    "output_songs_data = output_data + 'songs/songs.parquet'\n",
    "df_songs_table.write.partitionBy('year', 'artist_id').parquet(output_songs_data, 'overwrite')\n",
    "\n",
    "# Reload table to check\n",
    "start_time = time.time()\n",
    "df_songs_table_check = spark.read.parquet(output_songs_data.replace(\"s3a\", \"s3\"))\n",
    "print(\"Total time to run: {} seconds\".format(round((time.time() - start_time),4)))\n",
    "print(\"*\" * 50)\n",
    "\n",
    "df_songs_table_check.printSchema()\n",
    "df_songs_table_check.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f4aa12",
   "metadata": {},
   "source": [
    "# **<font color='indianred' face=\"Trebuchet MS\" size=\"4\" >1.2 Process `artists` table**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feb89557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb6db7db57e411e94f0e1942d97b52b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- latitude: float (nullable = true)\n",
      " |-- longitude: float (nullable = true)\n",
      "\n",
      "+------------------+------------+--------------+--------+---------+\n",
      "|         artist_id|        name|      location|latitude|longitude|\n",
      "+------------------+------------+--------------+--------+---------+\n",
      "|AR0IAWL1187B9A96D0|Danilo Perez|        Panama|  8.4177|-80.11278|\n",
      "|ARWB3G61187FB49404| Steve Morse|Hamilton, Ohio|    null|     null|\n",
      "+------------------+------------+--------------+--------+---------+\n",
      "only showing top 2 rows\n",
      "\n",
      "**************************************************\n",
      "Total time to run: 0.6307 seconds\n",
      "**************************************************\n",
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- latitude: float (nullable = true)\n",
      " |-- longitude: float (nullable = true)\n",
      "\n",
      "+------------------+----------------+------------------+--------+----------+\n",
      "|         artist_id|            name|          location|latitude| longitude|\n",
      "+------------------+----------------+------------------+--------+----------+\n",
      "|ARAADXM1187FB3ECDB|Styles Of Beyond|Woodland Hills, CA| 34.1688|-118.61092|\n",
      "|ARZJDBC1187FB52056|    Nasty Savage|  Brandon, Florida|27.94017| -82.32547|\n",
      "+------------------+----------------+------------------+--------+----------+\n",
      "only showing top 2 rows"
     ]
    }
   ],
   "source": [
    "# Create table\n",
    "df_artists_table = df_song_data.select('artist_id', 'artist_name', 'artist_location', 'artist_latitude', 'artist_longitude').dropDuplicates()\n",
    "\n",
    "# Rename columns\n",
    "column_names = [\"artist_id\", \"name\", \"location\", \"latitude\", \"longitude\"]\n",
    "df_artists_table = df_artists_table.toDF(*column_names)\n",
    "\n",
    "# Fix Datatypes\n",
    "df_artists_table = df_artists_table.withColumn(\"latitude\",col(\"latitude\").cast('float'))\n",
    "df_artists_table = df_artists_table.withColumn(\"longitude\",col(\"longitude\").cast('float'))\n",
    "\n",
    "# Create Temp View\n",
    "# df_artists_table.createOrReplaceTempView('artists_table')\n",
    "df_artists_table.printSchema()\n",
    "df_artists_table.show(2)\n",
    "print(\"*\" * 50)\n",
    "\n",
    "# Write table to s3 --> parquet files\n",
    "output_data = 's3a://maitys-sparkify-outputs/'\n",
    "output_artists_data = output_data + 'artists/artists.parquet'\n",
    "df_artists_table.write.parquet(output_artists_data, 'overwrite')\n",
    "\n",
    "# Reload table to check\n",
    "start_time = time.time()\n",
    "df_artists_table_check = spark.read.parquet(output_artists_data.replace(\"s3a\", \"s3\"))\n",
    "print(\"Total time to run: {} seconds\".format(round((time.time() - start_time),4)))\n",
    "print(\"*\" * 50)\n",
    "\n",
    "df_artists_table_check.printSchema()\n",
    "df_artists_table_check.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0eacb2",
   "metadata": {},
   "source": [
    "# **<font color='royalblue' face=\"Trebuchet MS\" size=\"5\" >2. Setup Function : `process_log_data`**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd319a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc20606531c648fc953a3c81d64d3464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to run: 10.1455 seconds\n",
      "**************************************************"
     ]
    }
   ],
   "source": [
    "# Set file Path\n",
    "input_data = \"s3://udacity-dend/\"\n",
    "input_log_data = input_data + 'log_data/2018/11/*.json'\n",
    "input_song_data = input_data + 'song_data/A/B/C/*.json'\n",
    "\n",
    "# Load raw data\n",
    "start_time = time.time()\n",
    "df_log_data = spark.read.json(input_log_data)\n",
    "df_song_data = spark.read.json(input_song_data)\n",
    "print(\"Total time to run: {} seconds\".format(round((time.time() - start_time),4)))\n",
    "print(\"*\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c371f65b",
   "metadata": {},
   "source": [
    "# **<font color='indianred' face=\"Trebuchet MS\" size=\"4\" >2.1 Process `users` table**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "518d863d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2449918f3d254ba8a7ebb1023f60929b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      "\n",
      "+-------+----------+---------+------+-----+\n",
      "|user_id|first_name|last_name|gender|level|\n",
      "+-------+----------+---------+------+-----+\n",
      "|     57| Katherine|      Gay|     F| free|\n",
      "|     22|      Sean|   Wilson|     F| free|\n",
      "+-------+----------+---------+------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "**************************************************\n",
      "Total time to run: 0.4432 seconds\n",
      "**************************************************\n",
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      "\n",
      "+-------+----------+---------+------+-----+\n",
      "|user_id|first_name|last_name|gender|level|\n",
      "+-------+----------+---------+------+-----+\n",
      "|     57| Katherine|      Gay|     F| free|\n",
      "|     22|      Sean|   Wilson|     F| free|\n",
      "+-------+----------+---------+------+-----+\n",
      "only showing top 2 rows"
     ]
    }
   ],
   "source": [
    "# Create table\n",
    "df_users_table = df_log_data.where((df_log_data.page == 'NextSong') & (df_log_data.userId.isNotNull()))\n",
    "df_users_table = df_users_table.select('userId', 'firstName', 'lastName', 'gender', 'level').dropDuplicates()\n",
    "\n",
    "# Rename columns\n",
    "column_names = [\"user_id\", \"first_name\", \"last_name\", \"gender\", \"level\"]\n",
    "df_users_table = df_users_table.toDF(*column_names)\n",
    "\n",
    "# Fix Datatypes\n",
    "df_users_table = df_users_table.withColumn(\"user_id\",col(\"user_id\").cast('integer'))\n",
    "\n",
    "# Create Temp View\n",
    "# df_users_table.createOrReplaceTempView('users_table')\n",
    "df_users_table.printSchema()\n",
    "df_users_table.show(2)\n",
    "print(\"*\" * 50)\n",
    "\n",
    "# Write table to s3 --> parquet files partitioned by level\n",
    "output_data = 's3a://maitys-sparkify-outputs/'\n",
    "output_users_data = output_data + 'users/users.parquet'\n",
    "df_users_table.write.partitionBy('level').parquet(output_users_data, 'overwrite')\n",
    "\n",
    "# Reload table to check\n",
    "start_time = time.time()\n",
    "df_users_table_check = spark.read.parquet(output_users_data.replace(\"s3a\", \"s3\"))\n",
    "print(\"Total time to run: {} seconds\".format(round((time.time() - start_time),4)))\n",
    "print(\"*\" * 50)\n",
    "\n",
    "df_users_table.printSchema()\n",
    "df_users_table.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb6401d",
   "metadata": {},
   "source": [
    "# **<font color='indianred' face=\"Trebuchet MS\" size=\"4\" >2.2 Process `time` table**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91684c5c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d432840842941649e47bc1cb47ae6e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- start_time: timestamp (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- weekday: integer (nullable = true)\n",
      "\n",
      "+--------------------+----+---+----+-----+----+-------+\n",
      "|          start_time|hour|day|week|month|year|weekday|\n",
      "+--------------------+----+---+----+-----+----+-------+\n",
      "|2018-11-28 16:10:...|  16| 28|  48|   11|2018|      4|\n",
      "|2018-11-05 04:40:...|   4|  5|  45|   11|2018|      2|\n",
      "+--------------------+----+---+----+-----+----+-------+\n",
      "only showing top 2 rows\n",
      "\n",
      "**************************************************\n",
      "Total time to run: 8.7331 seconds\n",
      "**************************************************\n",
      "root\n",
      " |-- start_time: timestamp (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      " |-- weekday: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n",
      "+--------------------+----+---+----+-------+----+-----+\n",
      "|          start_time|hour|day|week|weekday|year|month|\n",
      "+--------------------+----+---+----+-------+----+-----+\n",
      "|2018-11-28 05:13:...|   5| 28|  48|      4|2018|   11|\n",
      "|2018-11-28 08:18:...|   8| 28|  48|      4|2018|   11|\n",
      "+--------------------+----+---+----+-------+----+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 42722)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.6/socketserver.py\", line 320, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib64/python3.6/socketserver.py\", line 351, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib64/python3.6/socketserver.py\", line 364, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib64/python3.6/socketserver.py\", line 724, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 266, in handle\n",
      "    poll(authenticate_and_accum_updates)\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 254, in authenticate_and_accum_updates\n",
      "    received_token = self.rfile.read(len(auth_token))\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "----------------------------------------"
     ]
    }
   ],
   "source": [
    "# Create table\n",
    "df_time_table = df_log_data.where((df_log_data.page == 'NextSong') & (df_log_data.ts.isNotNull()))\n",
    "df_time_table = df_time_table.select('ts').dropDuplicates()\n",
    "\n",
    "# convert unix time to timestamp\n",
    "func_ts = udf(lambda ts: datetime.fromtimestamp(ts/1000).isoformat())\n",
    "df_time_table = df_time_table.withColumn('start_time', func_ts('ts').cast(TimestampType()))\n",
    "\n",
    "# add columns\n",
    "df_time_table = df_time_table.withColumn('hour', hour('start_time'))\n",
    "df_time_table = df_time_table.withColumn('day', dayofmonth('start_time'))\n",
    "df_time_table = df_time_table.withColumn('week', weekofyear('start_time'))\n",
    "df_time_table = df_time_table.withColumn('month', month('start_time'))\n",
    "df_time_table = df_time_table.withColumn('year', year('start_time'))\n",
    "df_time_table = df_time_table.withColumn('weekday', dayofweek('start_time'))\n",
    "\n",
    "# remove columns\n",
    "df_time_table = df_time_table.drop('ts')\n",
    "\n",
    "# Create Temp View\n",
    "# df_time_table.createOrReplaceTempView('time_table')\n",
    "df_time_table.printSchema()\n",
    "df_time_table.show(2)\n",
    "print(\"*\" * 50)\n",
    "\n",
    "# Write table to s3 --> parquet files partitioned by year and month\n",
    "output_data = 's3a://maitys-sparkify-outputs/'\n",
    "output_time_data = output_data + 'time/time.parquet'\n",
    "df_time_table.write.partitionBy('year', 'month').parquet(output_time_data, 'overwrite')\n",
    "\n",
    "# Reload table to check\n",
    "start_time = time.time()\n",
    "df_time_table_check = spark.read.parquet(output_time_data.replace(\"s3a\", \"s3\"))\n",
    "print(\"Total time to run: {} seconds\".format(round((time.time() - start_time),4)))\n",
    "print(\"*\" * 50)\n",
    "\n",
    "df_time_table_check.printSchema()\n",
    "df_time_table_check.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f47d3b",
   "metadata": {},
   "source": [
    "# **<font color='indianred' face=\"Trebuchet MS\" size=\"4\" >2.3 Process `songplays` table**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f5e6a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b001ffd2a1114c5595c9de761615c249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to run: 20.513 seconds\n",
      "**************************************************"
     ]
    }
   ],
   "source": [
    "# Set file Path\n",
    "input_data = \"s3://udacity-dend/\"\n",
    "input_log_data = input_data + 'log_data/2018/11/*.json'\n",
    "input_song_data = input_data + 'song_data/A/B/C/*.json'\n",
    "\n",
    "# Load raw data\n",
    "start_time = time.time()\n",
    "df_log_data = spark.read.json(input_log_data)\n",
    "df_song_data = spark.read.json(input_song_data)\n",
    "print(\"Total time to run: {} seconds\".format(round((time.time() - start_time),4)))\n",
    "print(\"*\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6eaddabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff55b62a79f548599a14fa488ae99f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create table\n",
    "df_songplays_table = df_log_data.join(df_song_data, (df_log_data.song == df_song_data.title) & (df_log_data.artist == df_song_data.artist_name), \n",
    "                                      how='inner')\n",
    "\n",
    "# Filter\n",
    "df_songplays_table = df_songplays_table.where((df_songplays_table.page == 'NextSong') & (df_songplays_table.ts.isNotNull()))\n",
    "\n",
    "# convert unix time to timestamp\n",
    "func_ts = udf(lambda ts: datetime.fromtimestamp(ts/1000).isoformat())\n",
    "df_songplays_table = df_songplays_table.withColumn('start_time', func_ts('ts').cast(TimestampType()))\n",
    "\n",
    "# Add songplay_id\n",
    "df_songplays_table = df_songplays_table.withColumn('songplay_id', monotonically_increasing_id())\n",
    "\n",
    "# Add columns\n",
    "df_songplays_table = df_songplays_table.withColumn('month', month('start_time'))\n",
    "df_songplays_table = df_songplays_table.withColumn('year', year('start_time'))\n",
    "\n",
    "# Select required columns\n",
    "df_songplays_table = df_songplays_table.select('songplay_id', 'start_time', 'userId', 'level', 'song_id', 'artist_id', 'sessionId', 'location', 'userAgent', 'month', 'year').dropDuplicates()\n",
    "\n",
    "# Rename columns\n",
    "column_names = ['songplay_id', 'start_time', 'user_id', 'level', 'song_id', 'artist_id', 'session_id', 'location', 'user_agent', 'month', 'year']\n",
    "df_songplays_table = df_songplays_table.toDF(*column_names)\n",
    "\n",
    "# Write table to s3 --> parquet files partitioned by year and month\n",
    "output_data = 's3a://maitys-sparkify-outputs/'\n",
    "output_songplays_data = output_data + 'songplays/songplays.parquet'\n",
    "df_songplays_table.write.partitionBy('year', 'month').parquet(output_songplays_data, 'overwrite')\n",
    "\n",
    "df_songplays_table.printSchema()\n",
    "df_songplays_table.show(2)\n",
    "\n",
    "# # Reload table to check\n",
    "# start_time = time.time()\n",
    "# df_songplays_table_check = spark.read.parquet(output_songplays_data.replace(\"s3a\", \"s3\"))\n",
    "# print(\"Total time to run: {} seconds\".format(round((time.time() - start_time),4)))\n",
    "# print(\"*\" * 50)\n",
    "\n",
    "# df_songplays_table_check.printSchema()\n",
    "# df_songplays_table_check.show(2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9f5d10ca4c21511749af540b671d84863cbfefa608d2fc62a2481134756e44f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('udacity_de_nd')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "python",
   "pygments_lexer": "python2",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
